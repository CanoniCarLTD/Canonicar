episode,step,timestep,actor_loss,critic_loss,entropy,action_std,step_reward,cumulative_reward
0,1,64,1.7752343794335875e+18,0.4175525695085526,-24.383926391601562,0.2,-5.0,-50.500000000000064
0,2,128,1.5074451149714318e+22,0.4603309631347656,-24.383926391601562,0.2,-0.1,-120.59999999999985
0,3,192,4.9466391104092896e+17,0.4209892123937607,-24.383926391601562,0.2,-0.1,-200.49999999999957
0,4,256,7.808508324629132e+18,0.4518048524856567,-24.383926391601562,0.2,-0.1,-270.5999999999996
0,5,320,3.539696366481709e+21,0.487536808848381,-24.383926391601562,0.2,-0.1,-330.90000000000083
0,6,384,1.6136682100941128e+18,0.4582158178091049,-24.383926391601562,0.2,-0.1,-405.90000000000197
0,7,448,1.8468916385390633e+19,0.473253059387207,-24.383926391601562,0.2,-0.1,-476.0000000000031
0,8,512,5.452345341136549e+18,0.45916561782360077,-24.383926391601562,0.2,-0.1,-546.1000000000042
