episode,step,timestep,actor_loss,critic_loss,entropy,action_std,step_reward,cumulative_reward
0,1,128,-0.27379326770703,0.8039743900299072,59.02028147379557,0.2,-0.17800000000000002,-14.655999999999999
0,130,-24.835,130,0.2,collision
1,2,256,-0.24671437591314316,0.4038780511667331,59.135500272115074,0.2,-0.17600000000000002,-14.300999999999998
1,3,384,-0.24290981640418371,0.40664127841591835,59.25071875254313,0.2,-0.30400000000000005,-45.085
1,4,512,-0.26730304087201756,0.8227432519197464,59.36593882242838,0.2,-0.43200000000000005,-92.25300000000006
1,5,640,-0.2558769869307677,0.4806511240700881,59.4811585744222,0.2,-0.56,-155.80499999999992
1,6,768,-0.257423506428798,0.43466321378946304,59.59637705485026,0.2,-0.6880000000000001,-235.74099999999993
1,770,-237.11999999999992,640.0,0.2,episode_length
2,7,896,-0.2745609792570273,0.5025674439966679,59.71159648895264,0.2,-0.8160000000000001,-94.94100000000006
